{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgilos/Bert-for-text-classification/blob/main/Active%2BBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S67cOg4MtLIE",
        "outputId": "566df43b-58ac-40dd-82fd-453430995816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bert-for-text-classification'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 165 (delta 12), reused 10 (delta 4), pack-reused 137 (from 1)\u001b[K\n",
            "Receiving objects: 100% (165/165), 36.83 MiB | 15.50 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ],
      "source": [
        "#cloning the repository\n",
        "#https://github.com/rmunro/pytorch_active_learning.git\n",
        "#https://github.com/georgilos/Bert-for-text-classification.git\n",
        "!git clone https://github.com/georgilos/Bert-for-text-classification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rkxQlxalKN8",
        "outputId": "05e50320-4623-4044-9600-d9463681e301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mBert-for-text-classification\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jegydkELtWMO",
        "outputId": "605120b2-f722-416a-f34f-af5f60d90083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Bert-for-text-classification\n"
          ]
        }
      ],
      "source": [
        "#changing directory to repository\n",
        "#%cd pytorch_active_learning/\n",
        "%cd Bert-for-text-classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ihIG5S17HN",
        "outputId": "d9366fb6-2856-451b-83b1-da3c94a2824e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esFECdj7lcz3"
      },
      "source": [
        "### Excecuting active_learning_basic.py with the SimpleTextClassifier swapped with bert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n4OlALQcPZvK",
        "outputId": "46a202fd-2781-4bea-fb10-0563fa0dd6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with current training data.\n",
            "Epoch: 1/3\n",
            "Average training loss: 0.570\n",
            "Epoch: 2/3\n",
            "Average training loss: 0.495\n",
            "Epoch: 3/3\n",
            "Average training loss: 0.444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fscore, auc, accuracy, precision, recall] = 0.0, 0.8172077574199078,0.915,0.0,0.0\n",
            "Model saved to: models/20241110_163626_0.0_0.817_0.915_0.0_0.0_404.params\n",
            "Sampling via Active Learning:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-2c0f466c145a>:559: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "web web → web web web bitcityz fediversefi fediverse bctz bcty jackdorsey\n",
            "\n",
            "> \n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "quite the idiotic comparisons\n",
            "\n",
            "> 1\n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "plus musical note nobodys buying nobodys buying cancelled musical note cnnplus bye bye bye\n",
            "\n",
            "> \n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "absolutely with his line of bullshit\n",
            "\n",
            "> 1\n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "peacocks aren ’ t proud they ’ re just horny\n",
            "\n",
            "> \n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "no he didn ’ t…\n",
            "\n",
            "> \n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "who had the displeasure of giving this dude head\n",
            "\n",
            "> 1\n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "you ’ re a bunch of losers\n",
            "\n",
            "> 1\n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "eat meat gt lift heavy rock flexed biceps\n",
            "\n",
            "> \n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "what a stupid fucking thing to say\n",
            "\n",
            "> 1\n",
            "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
            "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
            "\n",
            "no you weren ’ t\n",
            "\n",
            "> s\n",
            "\n",
            "Retraining model with new data\n",
            "Training model with updated training data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3\n",
            "Average training loss: 0.569\n",
            "Epoch: 2/3\n",
            "Average training loss: 0.490\n",
            "Epoch: 3/3\n",
            "Average training loss: 0.413\n",
            "[fscore, auc, accuracy, precision, recall] = 0.47058823529411764, 0.9128451016107719,0.94,0.9411764705882353,0.3137254901960784\n",
            "Model saved to: models/20241110_164223_0.471_0.913_0.94_0.941_0.314_414.params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-2c0f466c145a>:599: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fscore, auc, accuracy, precision, recall] = 0.47058823529411764, 0.9128451016107719,0.94,0.9411764705882353,0.3137254901960784\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2c0f466c145a>\u001b[0m in \u001b[0;36m<cell line: 612>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2c0f466c145a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mfscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[fscore, auc] = {fscore}, {auc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[fscore, auc] = {fscore}, {auc}\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"INTRODUCTION TO ACTIVE LEARNING\n",
        "\n",
        "A simple text classification algorithm in PyTorch\n",
        "\n",
        "This is an open source example to accompany Chapter 2 from the book:\n",
        "\"Human-in-the-Loop Machine Learning\"\n",
        "\n",
        "This example tries to classify news headlines into one of two categories:\n",
        "  disaster-related\n",
        "  not disaster-related\n",
        "\n",
        "It looks for low confidence items and outliers humans should review\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import math\n",
        "import datetime\n",
        "import csv\n",
        "import re\n",
        "import os\n",
        "from random import shuffle\n",
        "from collections import defaultdict\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW  # Use PyTorch's AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import logging\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "__author__ = \"Robert Munro\"\n",
        "__license__ = \"MIT\"\n",
        "__version__ = \"1.0.1\"\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# settings\n",
        "\n",
        "minimum_evaluation_items = 1200  # annotate this many randomly sampled items first for evaluation data before creating training data\n",
        "minimum_training_items = 400  # minimum number of training items before we first train a model\n",
        "\n",
        "epochs = 3  # number of epochs per training session\n",
        "select_per_epoch = 200  # number to select per epoch per label\n",
        "batch_size = 16  # Batch size for training\n",
        "\n",
        "data = []\n",
        "test_data = []\n",
        "\n",
        "# directories with data\n",
        "unlabeled_data = \"unlabeled_data/unlabeled_data.csv\"\n",
        "evaluation_related_data = \"evaluation_data/related.csv\"\n",
        "evaluation_not_related_data = \"evaluation_data/not_related.csv\"\n",
        "training_related_data = \"training_data/related.csv\"\n",
        "training_not_related_data = \"training_data/not_related.csv\"\n",
        "# validation_related_data # not used in this example\n",
        "# validation_not_related_data # not used in this example\n",
        "\n",
        "already_labeled = {}  # tracking what is already labeled\n",
        "\n",
        "def load_data(filepath, skip_already_labeled=False):\n",
        "    # csv format: [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
        "    data = []\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as csvfile:\n",
        "            reader = csv.reader(csvfile)\n",
        "            for row in reader:\n",
        "                if skip_already_labeled and row[0] in already_labeled:\n",
        "                    continue\n",
        "\n",
        "                # Ensure all necessary columns are present\n",
        "                while len(row) < 5:\n",
        "                    if len(row) == 2:\n",
        "                        row.append(\"\")  # LABEL\n",
        "                    elif len(row) == 3:\n",
        "                        row.append(\"\")  # SAMPLING_STRATEGY\n",
        "                    elif len(row) == 4:\n",
        "                        row.append(0)  # CONFIDENCE\n",
        "\n",
        "                data.append(row)\n",
        "\n",
        "                label = str(row[2])\n",
        "                if row[2] != \"\":\n",
        "                    textid = row[0]\n",
        "                    already_labeled[textid] = label\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"File not found: {filepath}\")\n",
        "    return data\n",
        "\n",
        "def append_data(filepath, data):\n",
        "    \"\"\"Append data to a CSV file.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'a', encoding='utf-8', errors='replace', newline='') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerows(data)\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"File not found: {filepath}\")\n",
        "\n",
        "def write_data(filepath, data):\n",
        "    \"\"\"Write data to a CSV file.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'w', encoding='utf-8', errors='replace', newline='') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerows(data)\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"File not found: {filepath}\")\n",
        "\n",
        "# LOAD ALL UNLABELED, TRAINING, VALIDATION, AND EVALUATION DATA\n",
        "training_data = load_data(training_related_data) + load_data(training_not_related_data)\n",
        "training_count = len(training_data)\n",
        "\n",
        "evaluation_data = load_data(evaluation_related_data) + load_data(evaluation_not_related_data)\n",
        "evaluation_count = len(evaluation_data)\n",
        "\n",
        "data = load_data(unlabeled_data, skip_already_labeled=True)\n",
        "\n",
        "annotation_instructions = (\n",
        "    \"Please type 1 if this message is disaster-related, \"\n",
        "    \"or hit Enter if not.\\n\"\n",
        "    \"Type 2 to go back to the last message, \"\n",
        "    \"type d to see detailed definitions, \"\n",
        "    \"or type s to save your annotations.\\n\"\n",
        ")\n",
        "\n",
        "last_instruction = (\n",
        "    \"All done!\\n\"\n",
        "    \"Type 2 to go back to change any labels,\\n\"\n",
        "    \"or Enter to save your annotations.\"\n",
        ")\n",
        "\n",
        "detailed_instructions = (\n",
        "    \"A 'hate-related' tweet is any sentence with foul language.\\n\"\n",
        "    \"It includes:\\n\"\n",
        "    \"  - offensive discourse targeting a group or an individual.\\n\"\n",
        "    \"  - use of slurs, based on inherent characteristics (race, religion or gender).\\n\"\n",
        "    \"  - glorification of war crimes.\\n\"\n",
        "    \"It does not include:\\n\"\n",
        "    \"  - Polite disagreements\\n\"\n",
        "    \"  - Non-agressive use of minority terms.\\n\\n\"\n",
        ")\n",
        "\n",
        "def get_annotations(data, default_sampling_strategy=\"random\"):\n",
        "    \"\"\"Prompts annotator for label from command line and adds annotations to data\n",
        "\n",
        "    Keyword arguments:\n",
        "        data -- a list of unlabeled items where each item is\n",
        "                [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
        "        default_sampling_strategy -- strategy to use for each item if not already specified\n",
        "    \"\"\"\n",
        "\n",
        "    ind = 0\n",
        "    while ind < len(data):\n",
        "        if ind < 0:\n",
        "            ind = 0  # in case you've gone back before the first\n",
        "        if ind < len(data):\n",
        "            textid = data[ind][0]\n",
        "            text = data[ind][1]\n",
        "            label = data[ind][2]\n",
        "            strategy = data[ind][3]\n",
        "\n",
        "            if textid in already_labeled:\n",
        "                print(f\"Skipping seen label: {label}\")\n",
        "                ind += 1\n",
        "            else:\n",
        "                print(annotation_instructions)\n",
        "                label_input = input(text + \"\\n\\n> \").strip()\n",
        "\n",
        "                if label_input == \"2\":\n",
        "                    ind -= 1  # go back\n",
        "                elif label_input == \"d\":\n",
        "                    print(detailed_instructions)  # print detailed instructions\n",
        "                elif label_input == \"s\":\n",
        "                    break  # save and exit\n",
        "                else:\n",
        "                    if label_input != \"1\":\n",
        "                        label = \"0\"  # treat everything other than 1 as 0\n",
        "                    else:\n",
        "                        label = \"1\"\n",
        "\n",
        "                    data[ind][2] = label  # add label to our data\n",
        "\n",
        "                    if not data[ind][3]:\n",
        "                        data[ind][3] = default_sampling_strategy  # add default if none given\n",
        "                    ind += 1\n",
        "\n",
        "        else:\n",
        "            # Last one - give annotator a chance to go back\n",
        "            print(last_instruction)\n",
        "            label_input = input(\"\\n\\n> \").strip()\n",
        "            if label_input == \"2\":\n",
        "                ind -= 1\n",
        "            else:\n",
        "                ind += 1\n",
        "\n",
        "    return data\n",
        "\n",
        "class BERTTextClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, max_seq_length):\n",
        "        super(BERTTextClassifier, self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)  # Use the pooled output for classification\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_seq_length):\n",
        "        self.input_ids = []\n",
        "        self.attention_masks = []\n",
        "        self.labels = []\n",
        "\n",
        "        for item in data:\n",
        "            try:\n",
        "                label = int(item[2])\n",
        "            except ValueError:\n",
        "                # If not, skip this item or assign a default label\n",
        "                logger.warning(f\"Skipping item with invalid label: {item[2]}\")  # Log the warning\n",
        "                print(f\"Skipping item with invalid label: {item[2]}\")  # Print to console\n",
        "                continue  # Skip this item\n",
        "            text = item[1]\n",
        "            encoded_input = tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=max_seq_length,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            # Avoid using torch.tensor on existing tensors\n",
        "            self.input_ids.append(encoded_input['input_ids'].clone().detach().squeeze(0))\n",
        "            self.attention_masks.append(encoded_input['attention_mask'].clone().detach().squeeze(0))\n",
        "            self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_masks[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "def train_model(training_data, validation_data, evaluation_data, num_labels=2):\n",
        "    \"\"\"Train model on the given training_data\n",
        "      Tune with the validation_data\n",
        "      Evaluate accuracy with the evaluation_data\n",
        "    \"\"\"\n",
        "    model = BERTTextClassifier(num_labels=num_labels, max_seq_length=128).to(device)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Prepare DataLoader\n",
        "    train_dataset = TextDataset(training_data, tokenizer, max_seq_length=128)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Optimizer & Scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)  # Use PyTorch's AdamW\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,  # Typically, warmup steps are a small fraction of total steps\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(epochs):\n",
        "        epoch_num = epoch + 1\n",
        "        logger.info(f\"Epoch: {epoch_num}/{epochs}\")\n",
        "        print(f\"Epoch: {epoch_num}/{epochs}\")  # Print epoch progress\n",
        "        model.train()\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "\n",
        "            loss = loss_function(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient Clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        logger.info(f\"Average training loss: {avg_train_loss:.3f}\")\n",
        "        print(f\"Average training loss: {avg_train_loss:.3f}\")  # Print training loss\n",
        "\n",
        "    fscore, auc, accuracy, precision, recall = evaluate_model(model, evaluation_data, tokenizer)\n",
        "    fscore = round(fscore, 3)\n",
        "    auc = round(auc, 3)\n",
        "    accuracy = round(accuracy, 3)\n",
        "    precision = round(precision, 3)\n",
        "    recall = round(recall, 3)\n",
        "\n",
        "    # Save model to path that is alphanumeric and includes number of items and accuracies in filename\n",
        "    timestamp = re.sub('\\.[0-9]*', '_', str(datetime.datetime.now())).replace(\" \", \"_\").replace(\"-\", \"\").replace(\":\", \"\")\n",
        "    training_size = \"_\" + str(len(training_data))\n",
        "    accuracies = f\"{fscore}_{auc}_{accuracy}_{precision}_{recall}\"\n",
        "\n",
        "    os.makedirs(\"models\", exist_ok=True)  # Ensure the models directory exists\n",
        "    model_path = f\"models/{timestamp}{accuracies}{training_size}.params\"\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    logger.info(f\"Model saved to: {model_path}\")\n",
        "    print(f\"Model saved to: {model_path}\")  # Print model save path\n",
        "    return model_path\n",
        "\n",
        "def evaluate_model(model, evaluation_data, tokenizer, batch_size=32):\n",
        "    \"\"\"Evaluate the model on the held-out evaluation data\n",
        "\n",
        "    Return the f-value for disaster-related and the AUC\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    dataset = TextDataset(evaluation_data, tokenizer, max_seq_length=128)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            probabilities = F.softmax(logits, dim=1)\n",
        "            probs_related = probabilities[:, 1].cpu().numpy()\n",
        "\n",
        "            all_probs.extend(probs_related.tolist())\n",
        "            all_labels.extend(labels.cpu().numpy().tolist())\n",
        "\n",
        "    # Calculate metrics using sklearn\n",
        "    binary_predictions = [1 if p > 0.5 else 0 for p in all_probs]  # Threshold at 0.5\n",
        "    fscore = f1_score(all_labels, binary_predictions)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "    accuracy = accuracy_score(all_labels, binary_predictions)  # Use binary predictions for accuracy\n",
        "    precision = precision_score(all_labels, binary_predictions)\n",
        "    recall = recall_score(all_labels, binary_predictions)\n",
        "\n",
        "    logger.info(f\"[fscore, auc, accuracy, precision, recall] = {fscore}, {auc},{accuracy},{precision},{recall}\")\n",
        "    print(f\"[fscore, auc, accuracy, precision, recall] = {fscore}, {auc},{accuracy},{precision},{recall}\")  # Print evaluation metrics\n",
        "    return [fscore, auc, accuracy, precision, recall]\n",
        "\n",
        "\n",
        "def get_low_conf_unlabeled(model, unlabeled_data, tokenizer, max_seq_length, number=80, limit=10000):\n",
        "    confidences = []\n",
        "    if limit == -1:  # Predicting on all data\n",
        "        logger.info(\"Get confidences for all unlabeled data (this might take a while)\")\n",
        "        print(\"Get confidences for all unlabeled data (this might take a while)\")\n",
        "    else:\n",
        "        # Only apply the model to a limited number of items\n",
        "        shuffle(unlabeled_data)\n",
        "        unlabeled_data = unlabeled_data[:limit]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for item in unlabeled_data:\n",
        "            textid = item[0]\n",
        "            if textid in already_labeled:\n",
        "                continue\n",
        "            item[3] = \"random_remaining\"\n",
        "            text = item[1]\n",
        "\n",
        "            encoded_input = tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=max_seq_length,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            input_ids = encoded_input['input_ids'].clone().detach().to(device)\n",
        "            attention_mask = encoded_input['attention_mask'].clone().detach().to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probabilities = F.softmax(logits, dim=1)\n",
        "            prob_related = probabilities[0][1].item()\n",
        "\n",
        "            if prob_related < 0.5:\n",
        "                confidence = 1 - prob_related\n",
        "            else:\n",
        "                confidence = prob_related\n",
        "\n",
        "            item[3] = \"low confidence\"\n",
        "            item[4] = confidence\n",
        "            confidences.append(item)\n",
        "\n",
        "    # Sort by confidence ascending\n",
        "    confidences.sort(key=lambda x: x[4])\n",
        "    return confidences[:number:]\n",
        "\n",
        "def get_random_items(unlabeled_data, number=10):\n",
        "    shuffle(unlabeled_data)\n",
        "    random_items = []\n",
        "    for item in unlabeled_data:\n",
        "        textid = item[0]\n",
        "        if textid in already_labeled:\n",
        "            continue\n",
        "        item[3] = \"random_remaining\"\n",
        "        random_items.append(item)\n",
        "        if len(random_items) >= number:\n",
        "            break\n",
        "\n",
        "    return random_items\n",
        "\n",
        "def get_outliers(training_data, unlabeled_data, number=10, max_iterations=1000):\n",
        "    \"\"\"Get outliers from unlabeled data in training data\n",
        "\n",
        "    Returns number outliers\n",
        "\n",
        "    An outlier is defined as the percent of words in an item in\n",
        "    unlabeled_data that do not exist in training_data\n",
        "    \"\"\"\n",
        "    outliers = []\n",
        "    total_feature_counts = defaultdict(lambda: 0)\n",
        "\n",
        "    for item in training_data:\n",
        "        text = item[1]\n",
        "        features = text.split()\n",
        "\n",
        "        for feature in features:\n",
        "            total_feature_counts[feature] += 1\n",
        "\n",
        "    iterations = 0\n",
        "    while (len(outliers) < number and iterations < max_iterations):\n",
        "        iterations += 1\n",
        "        top_outlier = []\n",
        "        top_match = float(\"inf\")\n",
        "\n",
        "        for item in unlabeled_data:\n",
        "            textid = item[0]\n",
        "            if textid in already_labeled:\n",
        "                continue\n",
        "\n",
        "            text = item[1]\n",
        "            features = text.split()\n",
        "\n",
        "            total_matches = 1  # start at 1 for slight smoothing\n",
        "            for feature in features:\n",
        "                if feature in total_feature_counts:\n",
        "                    total_matches += total_feature_counts[feature]\n",
        "\n",
        "            ave_matches = total_matches / len(features)\n",
        "            if ave_matches < top_match:\n",
        "                top_match = ave_matches\n",
        "                top_outlier = item\n",
        "\n",
        "        if not top_outlier:\n",
        "            break  # No outlier found\n",
        "\n",
        "        # Add this outlier to list and update what is 'labeled',\n",
        "        # assuming this new outlier will get a label\n",
        "        top_outlier[3] = \"outlier\"\n",
        "        outliers.append(top_outlier)\n",
        "        text = top_outlier[1]\n",
        "        features = text.split()\n",
        "        for feature in features:\n",
        "            total_feature_counts[feature] += 1\n",
        "\n",
        "    if iterations == max_iterations:\n",
        "        logger.warning(f\"Reached maximum iterations ({max_iterations}) without finding enough outliers.\")\n",
        "        print(f\"Reached maximum iterations ({max_iterations}) without finding enough outliers.\")\n",
        "\n",
        "    return outliers\n",
        "\n",
        "def main():\n",
        "\n",
        "    tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    global training_data, training_count, evaluation_data, evaluation_count, data\n",
        "\n",
        "    if evaluation_count < minimum_evaluation_items:\n",
        "        # Keep adding to evaluation data first\n",
        "        logger.info(\"Creating evaluation data:\\n\")\n",
        "        print(\"Creating evaluation data:\\n\")  # Print action\n",
        "\n",
        "        shuffle(data)\n",
        "        needed = minimum_evaluation_items - evaluation_count\n",
        "        selected_data = data[:needed]\n",
        "        logger.info(f\"{needed} more annotations needed\")\n",
        "        print(f\"{needed} more annotations needed\")  # Print needed annotations\n",
        "\n",
        "        annotated_data = get_annotations(selected_data)\n",
        "\n",
        "        related = [item for item in annotated_data if item[2] == \"1\"]\n",
        "        not_related = [item for item in annotated_data if item[2] == \"0\"]\n",
        "\n",
        "        # Append evaluation data\n",
        "        append_data(evaluation_related_data, related)\n",
        "        append_data(evaluation_not_related_data, not_related)\n",
        "\n",
        "    elif training_count < minimum_training_items:\n",
        "        # Let's create our first training data!\n",
        "        logger.info(\"Creating initial training data:\\n\")\n",
        "        print(\"Creating initial training data:\\n\")  # Print action\n",
        "\n",
        "        shuffle(data)\n",
        "        needed = minimum_training_items - training_count\n",
        "        selected_data = data[:needed]\n",
        "        logger.info(f\"{needed} more annotations needed\")\n",
        "        print(f\"{needed} more annotations needed\")  # Print needed annotations\n",
        "\n",
        "        annotated_data = get_annotations(selected_data)\n",
        "\n",
        "        related = [item for item in annotated_data if item[2] == \"1\"]\n",
        "        not_related = [item for item in annotated_data if item[2] == \"0\"]\n",
        "\n",
        "        # Append training data\n",
        "        append_data(training_related_data, related)\n",
        "        append_data(training_not_related_data, not_related)\n",
        "    else:\n",
        "        # Let's start Active Learning!!\n",
        "\n",
        "        # Train new model with current training data\n",
        "        logger.info(\"Training model with current training data.\")\n",
        "        print(\"Training model with current training data.\")  # Print action\n",
        "\n",
        "        model_path = train_model(training_data, None, evaluation_data)\n",
        "\n",
        "        logger.info(\"Sampling via Active Learning:\\n\")\n",
        "        print(\"Sampling via Active Learning:\\n\")  # Print action\n",
        "\n",
        "        model = BERTTextClassifier(num_labels=2, max_seq_length=128).to(device)\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "            model.to(device)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model from {model_path}: {e}\")\n",
        "            print(f\"Error loading model from {model_path}: {e}\")  # Print error\n",
        "            return\n",
        "\n",
        "        # Get items per iteration with the following breakdown of strategies:\n",
        "        random_items = get_random_items(data, number=10)\n",
        "        low_confidences = get_low_conf_unlabeled(model, data, tokenizer, 128, number=80)\n",
        "        outliers = get_outliers(training_data + random_items + low_confidences, data, number=10)\n",
        "\n",
        "        sampled_data = random_items + low_confidences + outliers\n",
        "        shuffle(sampled_data)\n",
        "\n",
        "        annotated_sampled_data = get_annotations(sampled_data)\n",
        "        related = [item for item in annotated_sampled_data if item[2] == \"1\"]\n",
        "        not_related = [item for item in annotated_sampled_data if item[2] == \"0\"]\n",
        "\n",
        "        # Append training data\n",
        "        append_data(training_related_data, related)\n",
        "        append_data(training_not_related_data, not_related)\n",
        "\n",
        "    if training_count > minimum_training_items:\n",
        "        logger.info(\"\\nRetraining model with new data\")\n",
        "        print(\"\\nRetraining model with new data\")  # Print action\n",
        "\n",
        "        # UPDATE OUR DATA AND (RE)TRAIN MODEL WITH NEWLY ANNOTATED DATA\n",
        "        training_data = load_data(training_related_data) + load_data(training_not_related_data)\n",
        "        training_count = len(training_data)\n",
        "\n",
        "        evaluation_data = load_data(evaluation_related_data) + load_data(evaluation_not_related_data)\n",
        "        evaluation_count = len(evaluation_data)\n",
        "\n",
        "        logger.info(\"Training model with updated training data.\")\n",
        "        print(\"Training model with updated training data.\")  # Print action\n",
        "\n",
        "        model_path = train_model(training_data, None, evaluation_data)\n",
        "        model = BERTTextClassifier(num_labels=2, max_seq_length=128).to(device)\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "            model.to(device)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model from {model_path}: {e}\")\n",
        "            print(f\"Error loading model from {model_path}: {e}\")  # Print error\n",
        "            return\n",
        "\n",
        "        fscore, auc = evaluate_model(model, evaluation_data, tokenizer)\n",
        "        logger.info(f\"[fscore, auc] = {fscore}, {auc}\")\n",
        "        print(f\"[fscore, auc] = {fscore}, {auc}\")  # Print evaluation metrics\n",
        "        logger.info(f\"Model saved to: {model_path}\")\n",
        "        print(f\"Model saved to: {model_path}\")  # Print model save path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-djbtcI6HsT"
      },
      "source": [
        "##Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9P-d2rPQS1J",
        "outputId": "68c8cad2-1793-4add-bc8b-e05a222e2c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "<ipython-input-13-02c529361dee>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/Bert-for-text-classification/models/20241105_204118_0.642_0.897_506.params\"))  # Replace with your model path\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence is predicted to be hatefull with confidence: 0.5089988708496094\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn as nn # Add this import statement\n",
        "from torch.nn import functional as F # Add this import statement\n",
        "\n",
        "class BERTTextClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, max_seq_length):\n",
        "        super(BERTTextClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased') # Use BertModel instead of transformers.BertModel\n",
        "        self.dropout = nn.Dropout(0.1)  # Adjust dropout rate as needed\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        pooled_output = outputs[1] #equivalent to outputs .pooler_output\n",
        "  # Use the pooled output for classification\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the tokenizer and model (assuming you have downloaded and saved them)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BERTTextClassifier(num_labels=2, max_seq_length=128).to(device)\n",
        "model.load_state_dict(torch.load(\"/content/Bert-for-text-classification/models/20241105_204118_0.642_0.897_506.params\"))  # Replace with your model path\n",
        "\n",
        "def predict(sentence):\n",
        "  \"\"\"\n",
        "  Classifies a new sentence using the loaded model.\n",
        "\n",
        "  Args:\n",
        "      sentence: The sentence to be classified (disaster-related or not).\n",
        "\n",
        "  Returns:\n",
        "      A tuple containing the predicted label (0 or 1) and the confidence score.\n",
        "  \"\"\"\n",
        "  # Preprocess the sentence\n",
        "  input_ids, attention_mask = make_feature_vector(sentence, tokenizer, max_seq_length=128)\n",
        "\n",
        "  # Make prediction\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_ids.to(device), attention_mask.to(device))\n",
        "    probabilities = F.softmax(logits, dim=1)\n",
        "    prob_related = probabilities[0][1].item()\n",
        "    predicted_label = 1 if prob_related > 0.5 else 0\n",
        "    return predicted_label, prob_related\n",
        "\n",
        "# Define the function to create feature vectors (assuming the make_feature_vector function is defined elsewhere)\n",
        "def make_feature_vector(text, tokenizer, max_seq_length):\n",
        "  # Implement your feature vector creation logic here (same as the original code)\n",
        "\n",
        "  tokens = tokenizer.encode_plus(text, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "  return tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "# Example usage\n",
        "new_sentence = \" Trump is an orange buffoon \"\n",
        "prediction, confidence = predict(new_sentence)\n",
        "\n",
        "if prediction == 1:\n",
        "  print(\"The sentence is predicted to be hatefull with confidence:\", confidence)\n",
        "else:\n",
        "  print(\"The sentence is predicted to not be hatefull with confidence:\", confidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9pD6fFtciSz"
      },
      "source": [
        "##Saving in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHCfWZZbb6ru",
        "outputId": "ce62326f-290b-4cc5-d1ef-8990fafe1c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiMZ3MHka_Vq"
      },
      "outputs": [],
      "source": [
        "#Save the .params file from colab to gdrive\n",
        "!cp /content/Bert-for-text-classification/models/20241105_204118_0.642_0.897_506.params /content/gdrive/MyDrive/Saved_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc2eclknXJwJ"
      },
      "source": [
        "### Loading from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mT1l8hfZDt1",
        "outputId": "10dbf6a6-edac-46fe-e0c2-2cc0d40be2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i50WRwSSXOaD"
      },
      "outputs": [],
      "source": [
        "#Save the .params file from google drive to the /models directory\n",
        "\n",
        "!cp /content/gdrive/MyDrive/Saved_models/20241105_204118_0.642_0.897_506.params /content/Bert-for-text-classification/models/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifying a .csv file using the .params file. File must contain a 'text' column. Output: classified_texts.csv  \n"
      ],
      "metadata": {
        "id": "Lf8qJ_qmQKgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Step 1: Define Your Custom Model Class\n",
        "class BERTTextClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, max_seq_length=512):\n",
        "        super(BERTTextClassifier, self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)  # Use the pooled output for classification\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Step 2: Load the Model with Your Saved Weights\n",
        "num_labels = 2  # Adjust to match your model's number of classes\n",
        "model = BERTTextClassifier(num_labels)\n",
        "model.load_state_dict(torch.load(\"/content/Bert-for-text-classification/models/20241105_204118_0.642_0.897_506.params\"))\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# Step 3: Define the Dataset Class to Preprocess New Data\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_seq_length=512):\n",
        "        self.input_ids = []\n",
        "        self.attention_masks = []\n",
        "\n",
        "        for text in texts:\n",
        "            encoded_input = tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=max_seq_length,\n",
        "                truncation=True,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            self.input_ids.append(encoded_input['input_ids'].squeeze(0))\n",
        "            self.attention_masks.append(encoded_input['attention_mask'].squeeze(0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_masks[idx]\n",
        "        }\n",
        "\n",
        "# Step 4: Load and Tokenize the .csv File Data\n",
        "df = pd.read_csv(\"your_file.csv\")\n",
        "text_data = df['text']  # Replace with your actual text column name\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "dataset = TextDataset(text_data, tokenizer, max_seq_length=512)\n",
        "dataloader = DataLoader(dataset, batch_size=32)  # Use a batch size for efficiency\n",
        "\n",
        "# Step 5: Run Predictions\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())  # Collect predictions\n",
        "\n",
        "# Step 6: Save Predictions to .CSV\n",
        "df['predictions'] = predictions\n",
        "df.to_csv(\"classified_texts.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "dcff5e6e7f364174881e03d89f9572fa",
            "b323071401964a35998142f082948cec",
            "2ad1344b301949899bbc1e626c011304",
            "623ffed795664c7ea8597861781ea9c8",
            "4a3f6572d61a4cf5b5d789b6e128e02c",
            "91e3db84cd2a45d690b4e5457ad4833f",
            "a73a543227c44b32b8a551cf23b4fda4",
            "00ff14bdcd5448c982a89861e1297bea",
            "a9984d0507794d6085134d8bf2b76339",
            "cdf642ba4bf34d25b7d182d0225ed301",
            "fda3f09d586f4039a87d8bbb796bfe98",
            "ebfff93a5c744e51aa2d537919afd7d2",
            "371d58ebd5324e1f915aac3cf65e8eb8",
            "51c57c8252e8493d8c080da4b83c2bf2",
            "a093b83011b7469b9c3beae5cdffe091",
            "1aeeda1c1f1045668bfdea6796dd4344",
            "f3a55916260e4a139bb1373fedf26a5a",
            "ba1c53f27cb6420187b9bcee5ce5aee5",
            "65ddea9670f24247ae5d250ebbda34c1",
            "e9cff1bc71e34bcca43fbc102194b119",
            "2cf4005d79e24699b07d45dd946e6c3b",
            "3877692980914eb88ea6e529ff893d30",
            "9a2c0da36b424f909255b28aa497b827",
            "d70eef46165544d6b0dad77fd7cda6b0",
            "d485d76575f74e56a424638839474d6a",
            "e4df0d5c6d014d47964989cd7b24bf5b",
            "e6e8028571b145df80dabd1cc0332bbc",
            "eff9f98e9c434c4394a0167b152a97f2",
            "71e14b29986f4d6da2fc137f7cb5a0ae",
            "3671a8b84e6745dbabf2e3786e7afef9",
            "317c7c12d7c64ab0a2597f7d4d9ce0fe",
            "6ef186770cdd4d7fa105dfdf6ca34e22",
            "c14c751884cc4adfa396651e431788c9",
            "ed825072cefa4d64bdb0d8518d7b3fff",
            "daba8f4d33ec4d518103a6edeccd0ab0",
            "2a04cac875444c238c8db6b0ae29c1dc",
            "009c80c0e3b24394b901c2c41039b69d",
            "2fad6622ab73407082ed71d86d42b82b",
            "8c1b7f1c2223461b955faad0ecb87fa2",
            "7aedf2b42f5b44c38869a88acb614868",
            "565b842214ed4537b368e6ac1ff6b1ae",
            "76da595928fa41068980bfad8ade4eda",
            "551abab67d0d448799cd54f7127c4ba6",
            "06553a708f394ca0b810979b391eef26",
            "5a19cc5c1dd64aa2a7502aaa04d3849e",
            "e960289a468a418aaf8dd71ae3d42501",
            "693d07e1dabb4e0d8efbcd98cd96897c",
            "272ca0aa3ac247f590546bcd203a00a7",
            "263955a190ec4cf7834af36490a6c735",
            "2a5acc20a7a9409ba033abe016ee9ed1",
            "86aa63fe94114a829fa72a0bab3a1022",
            "dd6c8c82c4134828ae9b8e3605e01f6d",
            "38e440bf3d0e424bb61cea124adb1fda",
            "227edd260e3442b0ab71711becd2eef8",
            "e3f47e5dd74b41b59865669d595fd4fe"
          ]
        },
        "id": "ALSXfVdOQX9T",
        "outputId": "7e8dd689-b90e-42f7-d7ef-f4b551ce5ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcff5e6e7f364174881e03d89f9572fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebfff93a5c744e51aa2d537919afd7d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d253437a3c06>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/Bert-for-text-classification/models/20241105_204118_0.642_0.897_506.params\"))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a2c0da36b424f909255b28aa497b827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed825072cefa4d64bdb0d8518d7b3fff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a19cc5c1dd64aa2a7502aaa04d3849e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMr8lxIn6G2bWMUDacv+lZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcff5e6e7f364174881e03d89f9572fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b323071401964a35998142f082948cec",
              "IPY_MODEL_2ad1344b301949899bbc1e626c011304",
              "IPY_MODEL_623ffed795664c7ea8597861781ea9c8"
            ],
            "layout": "IPY_MODEL_4a3f6572d61a4cf5b5d789b6e128e02c"
          }
        },
        "b323071401964a35998142f082948cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e3db84cd2a45d690b4e5457ad4833f",
            "placeholder": "​",
            "style": "IPY_MODEL_a73a543227c44b32b8a551cf23b4fda4",
            "value": "config.json: 100%"
          }
        },
        "2ad1344b301949899bbc1e626c011304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ff14bdcd5448c982a89861e1297bea",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9984d0507794d6085134d8bf2b76339",
            "value": 570
          }
        },
        "623ffed795664c7ea8597861781ea9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf642ba4bf34d25b7d182d0225ed301",
            "placeholder": "​",
            "style": "IPY_MODEL_fda3f09d586f4039a87d8bbb796bfe98",
            "value": " 570/570 [00:00&lt;00:00, 47.5kB/s]"
          }
        },
        "4a3f6572d61a4cf5b5d789b6e128e02c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e3db84cd2a45d690b4e5457ad4833f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73a543227c44b32b8a551cf23b4fda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ff14bdcd5448c982a89861e1297bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9984d0507794d6085134d8bf2b76339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdf642ba4bf34d25b7d182d0225ed301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda3f09d586f4039a87d8bbb796bfe98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebfff93a5c744e51aa2d537919afd7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_371d58ebd5324e1f915aac3cf65e8eb8",
              "IPY_MODEL_51c57c8252e8493d8c080da4b83c2bf2",
              "IPY_MODEL_a093b83011b7469b9c3beae5cdffe091"
            ],
            "layout": "IPY_MODEL_1aeeda1c1f1045668bfdea6796dd4344"
          }
        },
        "371d58ebd5324e1f915aac3cf65e8eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a55916260e4a139bb1373fedf26a5a",
            "placeholder": "​",
            "style": "IPY_MODEL_ba1c53f27cb6420187b9bcee5ce5aee5",
            "value": "model.safetensors: 100%"
          }
        },
        "51c57c8252e8493d8c080da4b83c2bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ddea9670f24247ae5d250ebbda34c1",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9cff1bc71e34bcca43fbc102194b119",
            "value": 440449768
          }
        },
        "a093b83011b7469b9c3beae5cdffe091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf4005d79e24699b07d45dd946e6c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_3877692980914eb88ea6e529ff893d30",
            "value": " 440M/440M [00:01&lt;00:00, 253MB/s]"
          }
        },
        "1aeeda1c1f1045668bfdea6796dd4344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a55916260e4a139bb1373fedf26a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1c53f27cb6420187b9bcee5ce5aee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65ddea9670f24247ae5d250ebbda34c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9cff1bc71e34bcca43fbc102194b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cf4005d79e24699b07d45dd946e6c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3877692980914eb88ea6e529ff893d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a2c0da36b424f909255b28aa497b827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d70eef46165544d6b0dad77fd7cda6b0",
              "IPY_MODEL_d485d76575f74e56a424638839474d6a",
              "IPY_MODEL_e4df0d5c6d014d47964989cd7b24bf5b"
            ],
            "layout": "IPY_MODEL_e6e8028571b145df80dabd1cc0332bbc"
          }
        },
        "d70eef46165544d6b0dad77fd7cda6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff9f98e9c434c4394a0167b152a97f2",
            "placeholder": "​",
            "style": "IPY_MODEL_71e14b29986f4d6da2fc137f7cb5a0ae",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d485d76575f74e56a424638839474d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3671a8b84e6745dbabf2e3786e7afef9",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_317c7c12d7c64ab0a2597f7d4d9ce0fe",
            "value": 48
          }
        },
        "e4df0d5c6d014d47964989cd7b24bf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef186770cdd4d7fa105dfdf6ca34e22",
            "placeholder": "​",
            "style": "IPY_MODEL_c14c751884cc4adfa396651e431788c9",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.36kB/s]"
          }
        },
        "e6e8028571b145df80dabd1cc0332bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff9f98e9c434c4394a0167b152a97f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e14b29986f4d6da2fc137f7cb5a0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3671a8b84e6745dbabf2e3786e7afef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317c7c12d7c64ab0a2597f7d4d9ce0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ef186770cdd4d7fa105dfdf6ca34e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14c751884cc4adfa396651e431788c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed825072cefa4d64bdb0d8518d7b3fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daba8f4d33ec4d518103a6edeccd0ab0",
              "IPY_MODEL_2a04cac875444c238c8db6b0ae29c1dc",
              "IPY_MODEL_009c80c0e3b24394b901c2c41039b69d"
            ],
            "layout": "IPY_MODEL_2fad6622ab73407082ed71d86d42b82b"
          }
        },
        "daba8f4d33ec4d518103a6edeccd0ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1b7f1c2223461b955faad0ecb87fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_7aedf2b42f5b44c38869a88acb614868",
            "value": "vocab.txt: 100%"
          }
        },
        "2a04cac875444c238c8db6b0ae29c1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565b842214ed4537b368e6ac1ff6b1ae",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76da595928fa41068980bfad8ade4eda",
            "value": 231508
          }
        },
        "009c80c0e3b24394b901c2c41039b69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551abab67d0d448799cd54f7127c4ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_06553a708f394ca0b810979b391eef26",
            "value": " 232k/232k [00:00&lt;00:00, 15.4MB/s]"
          }
        },
        "2fad6622ab73407082ed71d86d42b82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1b7f1c2223461b955faad0ecb87fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aedf2b42f5b44c38869a88acb614868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565b842214ed4537b368e6ac1ff6b1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76da595928fa41068980bfad8ade4eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "551abab67d0d448799cd54f7127c4ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06553a708f394ca0b810979b391eef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a19cc5c1dd64aa2a7502aaa04d3849e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e960289a468a418aaf8dd71ae3d42501",
              "IPY_MODEL_693d07e1dabb4e0d8efbcd98cd96897c",
              "IPY_MODEL_272ca0aa3ac247f590546bcd203a00a7"
            ],
            "layout": "IPY_MODEL_263955a190ec4cf7834af36490a6c735"
          }
        },
        "e960289a468a418aaf8dd71ae3d42501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5acc20a7a9409ba033abe016ee9ed1",
            "placeholder": "​",
            "style": "IPY_MODEL_86aa63fe94114a829fa72a0bab3a1022",
            "value": "tokenizer.json: 100%"
          }
        },
        "693d07e1dabb4e0d8efbcd98cd96897c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd6c8c82c4134828ae9b8e3605e01f6d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38e440bf3d0e424bb61cea124adb1fda",
            "value": 466062
          }
        },
        "272ca0aa3ac247f590546bcd203a00a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_227edd260e3442b0ab71711becd2eef8",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f47e5dd74b41b59865669d595fd4fe",
            "value": " 466k/466k [00:00&lt;00:00, 2.12MB/s]"
          }
        },
        "263955a190ec4cf7834af36490a6c735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5acc20a7a9409ba033abe016ee9ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86aa63fe94114a829fa72a0bab3a1022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6c8c82c4134828ae9b8e3605e01f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e440bf3d0e424bb61cea124adb1fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "227edd260e3442b0ab71711becd2eef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f47e5dd74b41b59865669d595fd4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}